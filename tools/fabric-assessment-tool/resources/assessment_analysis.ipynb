{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beccd07e",
   "metadata": {},
   "source": [
    "# Assessment Results Analysis with DuckDB\n",
    "\n",
    "This notebook demonstrates how to analyze assessment results from the Fabric Assessment Tool using DuckDB. The tool exports data in a hierarchical folder structure that enables efficient querying and analysis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Fabric Assessment Tool now exports assessment data in a structured format with separate folders for:\n",
    "- **Resources**: Notebooks, jobs/pipelines, clusters/pools  \n",
    "- **Admin**: Administrative components (Synapse only)\n",
    "- **Data**: Hierarchical data structure with databases → schemas → tables/views\n",
    "\n",
    "This structure enables granular analysis and better understanding of your data platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DuckDB if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import duckdb\n",
    "    print(\"DuckDB is already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing DuckDB...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"duckdb\"])\n",
    "    import duckdb\n",
    "    print(\"DuckDB installed successfully\")\n",
    "\n",
    "# Initialize DuckDB connection\n",
    "conn = duckdb.connect()\n",
    "print(\"DuckDB connection established\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd08b79",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the path to your assessment results. Update the `assessment_path` variable to point to your exported assessment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f610c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Update this path to point to your assessment results\n",
    "assessment_path = \"/path/to/your/assessment/results\"\n",
    "\n",
    "# Example paths:\n",
    "# assessment_path = \"/tmp/assessment\"\n",
    "# assessment_path = \"C:/assessments/my_workspace\"\n",
    "# assessment_path = \"/home/user/fabric_assessment_results\"\n",
    "\n",
    "print(f\"Assessment path: {assessment_path}\")\n",
    "print(\"\\nMake sure to update the 'assessment_path' variable above to point to your actual assessment results directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad9802",
   "metadata": {},
   "source": [
    "## Synapse Assessment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a21473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Synapse tables for analysis\n",
    "\n",
    "# Notebooks\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE synapse_notebooks AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/resources/notebooks/*.json');\n",
    "\"\"\")\n",
    "\n",
    "# SQL Pools\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE synapse_sql_pools AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/resources/sql_pools/*.json');\n",
    "\"\"\")\n",
    "\n",
    "# Serverless Databases\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE synapse_serverless_databases AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/data/serverless_databases/databases/*/*.json');\n",
    "\"\"\")\n",
    "\n",
    "# Serverless Schemas\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE synapse_serverless_schemas AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/data/serverless_databases/databases/*/schemas/*/*.json');\n",
    "\"\"\")\n",
    "\n",
    "# Serverless Tables\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE synapse_serverless_tables AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/data/serverless_databases/databases/*/schemas/*/tables/*.json');\n",
    "\"\"\")\n",
    "\n",
    "# Dedicated Tables\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE synapse_dedicated_tables AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/data/dedicated_databases/databases/*/schemas/*/tables/*.json');\n",
    "\"\"\")\n",
    "\n",
    "print(\"Synapse assessment tables created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Synapse notebooks by language\n",
    "notebook_analysis = conn.execute(\"\"\"\n",
    "SELECT data.language AS language, \n",
    "       COUNT(*) AS notebook_count \n",
    "FROM synapse_notebooks \n",
    "GROUP BY data.language\n",
    "ORDER BY notebook_count DESC;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Synapse Notebooks by Language:\")\n",
    "print(notebook_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Synapse dedicated table statistics\n",
    "dedicated_stats = conn.execute(\"\"\"\n",
    "SELECT data.name AS table_name,\n",
    "       data.database,\n",
    "       data.schema,\n",
    "       data.statistics.distribution_policy_name AS distribution_policy,\n",
    "       data.statistics.table_row_count AS row_count,\n",
    "       CAST(data.statistics.table_reserved_space_gb AS DECIMAL(18,3)) AS reserved_space_gb,\n",
    "       CAST(data.statistics.table_data_space_gb AS DECIMAL(18,3)) AS data_space_gb\n",
    "FROM synapse_dedicated_tables\n",
    "WHERE type = 'table' AND data.statistics IS NOT NULL\n",
    "ORDER BY data_space_gb DESC\n",
    "LIMIT 10;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Top 10 Synapse Dedicated Tables by Size:\")\n",
    "print(dedicated_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ae177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate statistics by database and distribution policy\n",
    "distribution_summary = conn.execute(\"\"\"\n",
    "SELECT data.database as database,\n",
    "       data.statistics.distribution_policy_name AS distribution_policy,\n",
    "       SUM(data.statistics.table_row_count) AS total_rows,\n",
    "       SUM(CAST(data.statistics.table_reserved_space_gb AS DECIMAL(18,3))) AS total_reserved_gb,\n",
    "       SUM(CAST(data.statistics.table_data_space_gb AS DECIMAL(18,3))) AS total_data_gb,\n",
    "       COUNT(*) AS table_count\n",
    "FROM synapse_dedicated_tables\n",
    "WHERE type = 'table' AND data.statistics IS NOT NULL\n",
    "GROUP BY database, distribution_policy\n",
    "ORDER BY total_data_gb DESC;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Synapse Tables by Database and Distribution Policy:\")\n",
    "print(distribution_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1159ac3",
   "metadata": {},
   "source": [
    "## Databricks Assessment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5858babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Databricks tables for analysis\n",
    "\n",
    "# Unity Catalog\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE databricks_catalogs AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/data/unity_catalog/catalogs/*/*.json');\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE databricks_schemas AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/data/unity_catalog/catalogs/*/schemas/*/*.json');\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE databricks_tables AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/data/unity_catalog/catalogs/*/schemas/*/tables/*.json', union_by_name=True);\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE databricks_volumes AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/data/unity_catalog/catalogs/*/schemas/*/volumes/*.json');\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE databricks_functions AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/data/unity_catalog/catalogs/*/schemas/*/functions/*.json');\n",
    "\"\"\")\n",
    "\n",
    "# Clusters and Jobs\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE databricks_clusters AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/resources/clusters/*.json');\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE databricks_jobs AS\n",
    "SELECT * FROM read_json_auto('{assessment_path}/*/resources/jobs/*.json');\n",
    "\"\"\")\n",
    "\n",
    "print(\"Databricks assessment tables created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Databricks Unity Catalog structure\n",
    "catalog_analysis = conn.execute(\"\"\"\n",
    "SELECT data.name AS catalog_name,\n",
    "       data.comment,\n",
    "       data.owner,\n",
    "       data.storage_root\n",
    "FROM databricks_catalogs\n",
    "WHERE type = 'unity_catalog';\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Databricks Unity Catalogs:\")\n",
    "print(catalog_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tables by format in Unity Catalog\n",
    "table_format_analysis = conn.execute(\"\"\"\n",
    "SELECT data.catalog AS catalog_name,\n",
    "       data.format,\n",
    "       COUNT(*) AS table_count,\n",
    "       SUM(data.statistics_size_bytes)/1073741824 AS total_size_gigabytes,\n",
    "       SUM(data.statistics_row_count)/1000000 AS total_million_row_count\n",
    "FROM databricks_tables\n",
    "WHERE type = 'table' AND data.format IS NOT NULL\n",
    "GROUP BY catalog_name, data.format\n",
    "ORDER BY catalog_name, table_count DESC;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Databricks Tables by Format:\")\n",
    "print(table_format_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94025ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find tables with many columns\n",
    "complex_tables = conn.execute(\"\"\"\n",
    "SELECT data.name AS table_name,\n",
    "       data.catalog AS catalog_name,\n",
    "       data.schema AS schema_name,\n",
    "       data.columns AS column_count,\n",
    "       data.statistics_size_bytes / (1024 * 1024) AS size_megabytes\n",
    "FROM databricks_tables\n",
    "WHERE type = 'table' AND data.columns > 20\n",
    "ORDER BY data.columns DESC\n",
    "LIMIT 10;\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Tables with Most Columns:\")\n",
    "print(complex_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfc91c",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrates how to analyze assessment results using the hierarchical folder structure. The key benefits include:\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Customize the queries for your specific analysis needs\n",
    "- Add visualizations using matplotlib, plotly, or other libraries\n",
    "- Export results to different formats (CSV, Excel, etc.)\n",
    "- Create automated reports based on the assessment data\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Query Results Guide](../docs/query_results.md): Comprehensive examples of DuckDB queries\n",
    "- [DuckDB Documentation](https://duckdb.org/docs/): Official DuckDB documentation\n",
    "- [Fabric Assessment Tool Repository](https://github.com/microsoft/lakelense): Source code and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
