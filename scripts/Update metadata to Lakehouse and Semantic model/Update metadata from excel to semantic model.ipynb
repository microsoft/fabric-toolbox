{"cells":[{"cell_type":"code","source":["%pip install semantic-link-labs --quiet"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[3,4,5,6,7],"state":"finished","livy_statement_state":"available","session_id":"0bdfba23-0cec-47ef-90aa-50fdb43b8841","normalized_state":"finished","queued_time":"2025-12-08T20:49:07.2022091Z","session_start_time":"2025-12-08T20:49:07.2025641Z","execution_start_time":"2025-12-08T20:49:19.867766Z","execution_finish_time":"2025-12-08T20:49:39.7578889Z","parent_msg_id":"bdfd15d6-d207-45df-b99b-8290327807d0"},"text/plain":"StatementMeta(, 0bdfba23-0cec-47ef-90aa-50fdb43b8841, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"outputs_hidden":false}},"id":"abae4617-f9e7-4ac0-926f-dd8300b2aa1f"},{"cell_type":"code","source":["#imports & config\n","from pyspark.sql import functions as F\n","from pyspark.sql import types as T\n","import json\n","import pandas as pd\n","from collections import defaultdict\n","\n","from sempy_labs.tom import connect_semantic_model\n","\n","# -----------------------------\n","# User configuration (edit these)\n","WORKSPACE_NAME        = \"WS_AutoClaimsPOC\"\n","SEMANTIC_MODEL_NAME   = \"sm_AutoClaims\"\n","EXCEL_FILE_PATH       = \"abfss://WS_AutoClaimsPOC@onelake.dfs.fabric.microsoft.com/lh_AutoClaims.Lakehouse/Files/Data Catalog/sample_data_catalog.xlsx\"\n","\n","# Optional: Filter specific tables (empty list = all tables from Excel)\n","INCLUDE_TABLES = []  # e.g., [\"businessunitreference\", \"portfolio\"]\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"0bdfba23-0cec-47ef-90aa-50fdb43b8841","normalized_state":"finished","queued_time":"2025-12-08T20:49:47.2433603Z","session_start_time":null,"execution_start_time":"2025-12-08T20:49:53.0902304Z","execution_finish_time":"2025-12-08T20:49:56.5351852Z","parent_msg_id":"7592c051-6a39-4a3d-a6d2-54aadb9a8f69"},"text/plain":"StatementMeta(, 0bdfba23-0cec-47ef-90aa-50fdb43b8841, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0ffd9766-816f-45a5-b665-40802dc7ff6c"},{"cell_type":"code","source":["# -----------------------------\n","# Load and process Excel file\n","print(\"Loading Excel file...\")\n","df_excel = pd.read_excel(EXCEL_FILE_PATH)\n","df_excel = df_excel.replace({r'\\r\\n|\\n|\\r': ' '}, regex=True)\n","\n","# Convert to Spark DataFrame\n","df_spark = spark.createDataFrame(df_excel)\n","df_spark = df_spark.select(\"Logical Table Name\", \"Logical Field Name\", \"Data Team Definition\").dropDuplicates()\n","\n","print(f\"Loaded {df_spark.count()} rows from Excel\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"0bdfba23-0cec-47ef-90aa-50fdb43b8841","normalized_state":"finished","queued_time":"2025-12-08T20:50:16.3797802Z","session_start_time":null,"execution_start_time":"2025-12-08T20:50:16.3809335Z","execution_finish_time":"2025-12-08T20:50:22.5404435Z","parent_msg_id":"458ef0c4-f735-42bc-a5c8-8333ec1cca1e"},"text/plain":"StatementMeta(, 0bdfba23-0cec-47ef-90aa-50fdb43b8841, 10, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loading Excel file...\nLoaded 65 rows from Excel\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f3d2b892-fe42-47e5-9ccd-5112a308bb95"},{"cell_type":"code","source":["# Group metadata by table and column\n","metadata_map = {}\n","\n","rows = df_spark.collect()\n","for row in rows:\n","    table_name = row['Logical Table Name']\n","    field_name = row['Logical Field Name']\n","    description = row['Data Team Definition']\n","    \n","    if table_name is None or field_name is None:\n","        continue\n","    \n","    table_name = str(table_name).strip().lower()\n","    field_name = str(field_name).strip()\n","    description = str(description).strip() if description is not None else \"\"\n","    \n","    # Filter by INCLUDE_TABLES if specified\n","    if INCLUDE_TABLES and table_name not in [t.lower() for t in INCLUDE_TABLES]:\n","        continue\n","    \n","    # Set table description\n","    if table_name not in metadata_map:\n","        metadata_map[table_name] = {\n","            \"table_description\": f\"Table: {table_name}\",\n","            \"columns\": {}\n","        }\n","\n","    # Store column description\n","    if description:\n","        metadata_map[table_name][\"columns\"][field_name] = description\n","\n","print(f\"Processed metadata for {len(metadata_map)} tables from Excel\")\n","print(metadata_map)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"0bdfba23-0cec-47ef-90aa-50fdb43b8841","normalized_state":"finished","queued_time":"2025-12-08T20:50:31.5197668Z","session_start_time":null,"execution_start_time":"2025-12-08T20:50:31.5209805Z","execution_finish_time":"2025-12-08T20:50:32.3002749Z","parent_msg_id":"6f6bae6f-447a-4f90-9f24-04cd193b48a6"},"text/plain":"StatementMeta(, 0bdfba23-0cec-47ef-90aa-50fdb43b8841, 11, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processed metadata for 8 tables from Excel\n{'accident': {'table_description': 'Table: accident', 'columns': {'accident_date': 'Date when the accident occurred', 'vehicle_vin': 'Vehicle Identification Number of the vehicle involved in the accident', 'policyholder_id': 'Foreign key referencing the policyholder involved in the accident', 'accident_id': 'Unique identifier for each accident record', 'severity': 'Severity level of the accident (Low, Medium, High) indicating the extent of damage or injury', 'accident_type': 'Type or category of accident (e.g., Rear-end collision, Side impact, Single vehicle)', 'location': 'City or location where the accident took place'}}, 'adjuster': {'table_description': 'Table: adjuster', 'columns': {'id': 'Unique identifier for each claims adjuster', 'phone': 'Contact phone number for the adjuster', 'name': 'Full name of the claims adjuster', 'email': 'Email address for the adjuster'}}, 'claim': {'table_description': 'Table: claim', 'columns': {'claim_number': \"Unique claim identifier starting with 'CLM' prefix\", 'accident_id': 'Foreign key referencing the accident that triggered the claim', 'date_filed': 'Date when the claim was filed by the policyholder', 'status': 'Current status of the claim (e.g., Closed, Open, Pending)', 'policy_number': 'Foreign key referencing the insurance policy associated with the claim', 'payout_amount': 'Actual amount paid out by the insurance company after claim assessment', 'claim_amount': 'Total amount claimed by the policyholder for damages and losses', 'adjuster_id': 'Foreign key referencing the adjuster assigned to handle the claim'}}, 'driver_telemetry_data': {'table_description': 'Table: driver_telemetry_data', 'columns': {'vin': 'Vehicle Identification Number of the vehicle used during the trip', 'policyholder_id': 'Foreign key referencing the policyholder who made the trip', 'End_Time': 'Date and time when the trip ended (ISO 8601 format with timezone)', 'Start_Time': 'Date and time when the trip started (ISO 8601 format with timezone)', 'Trip_ID': 'Unique identifier for each driving trip, combining policyholder ID, VIN, and trip sequence number', 'Peak_High_Speed': 'Maximum speed reached during the trip in miles per hour', 'Distance_Miles': 'Total distance traveled during the trip in miles', 'Time_of_Day_Category': 'Time period categorization of the trip (Morning, Afternoon, Evening, Night)', 'Duration_Min': 'Total duration of the trip in minutes', 'Peak_Low_Speed': 'Minimum speed recorded during the trip in miles per hour', 'Start_Location_Lon': 'Longitude coordinate of the trip starting location', 'Average_Speed': 'Average speed maintained throughout the trip in miles per hour', 'Start_Location_Lat': 'Latitude coordinate of the trip starting location', 'Sudden_Braking_Count': 'Number of sudden braking events detected during the trip', 'Max_Speed_Limit_Exceeded': 'Maximum amount by which the speed limit was exceeded during the trip in miles per hour', 'Harsh_Cornering_Count': 'Number of harsh cornering or sharp turning events during the trip', 'Safety_Score': 'Overall safety rating for the trip based on driving behavior metrics (0-100 scale)', 'Acceleration_Index': 'Normalized index measuring acceleration behavior quality (0-1 scale)', 'Rapid_Acceleration_Count': 'Number of rapid acceleration events detected during the trip', 'Speeding_Incidents': 'Total number of speeding incidents recorded during the trip', 'Braking_Index': 'Normalized index measuring braking behavior quality (0-1 scale)', 'Trip_Risk_Level': 'Overall risk classification for the trip based on driving metrics (Low, Medium, High)'}}, 'payment': {'table_description': 'Table: payment', 'columns': {'payment_id': \"Unique payment identifier starting with 'PAY' prefix\", 'claim_number': 'Foreign key referencing the claim for which payment was made', 'payment_method': 'Method used for payment disbursement (e.g., Check, Direct Deposit)', 'payment_date': 'Date when the payment was processed and issued', 'payment_amount': 'Amount paid to the claimant in dollars'}}, 'policy': {'table_description': 'Table: policy', 'columns': {'policyholder_id': 'Foreign key referencing the policyholder who owns the policy', 'policy_number': \"Unique policy identifier starting with 'POL' prefix\", 'vehicle_vin': 'Vehicle Identification Number of the insured vehicle', 'coverage_type': 'Type of insurance coverage (e.g., Comprehensive, Third Party)', 'premium': 'Annual premium amount charged for the insurance policy in dollars', 'start_date': 'Effective start date of the insurance policy coverage period', 'end_date': 'Expiration date of the insurance policy coverage period'}}, 'policyholder': {'table_description': 'Table: policyholder', 'columns': {'id': 'Unique identifier for each policyholder', 'address': \"Street address of the policyholder's residence\", 'name': 'Full name of the policyholder', 'phone': 'Primary contact phone number for the policyholder', 'city': 'City where the policyholder resides', 'email': 'Email address for policyholder communications', 'state': \"Two-letter state code for the policyholder's state of residence\", 'date_of_birth': 'Date of birth of the policyholder used for age verification and risk assessment'}}, 'vehicle': {'table_description': 'Table: vehicle', 'columns': {'year': 'Manufacturing year of the vehicle', 'vin': 'Vehicle Identification Number - unique 17-character identifier for each vehicle', 'model': 'Model name of the vehicle (e.g., Corolla, Civic, Focus)', 'make': 'Manufacturer or brand of the vehicle (e.g., Toyota, Honda, Ford)'}}}\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"105bdd58-c1cf-4fd9-8f48-e15e51dac1c5"},{"cell_type":"code","source":["updates_applied = []\n","missing_tables = []\n","missing_columns = []\n","\n","# Loop through semantic model tables and columns\n","with connect_semantic_model(dataset=SEMANTIC_MODEL_NAME, workspace=WORKSPACE_NAME, readonly=False) as tom:\n","    \n","    # Get list of semantic model tables for comparison\n","    sem_model_tables = {t.Name.lower(): t for t in tom.model.Tables}\n","    \n","    for table_name, table_data in metadata_map.items():\n","        \n","        # Check if table exists in semantic model (case-insensitive)\n","        if table_name not in sem_model_tables:\n","            missing_tables.append(table_name)\n","            print(f\"⚠ Table not found in semantic model: {table_name}\")\n","            continue\n","        \n","        # Get the actual table object\n","        table_obj = sem_model_tables[table_name]\n","\n","        # Update table description\n","        table_description = table_data[\"table_description\"]\n","        if table_description:\n","            table_obj.Description = table_description\n","            updates_applied.append((\"TABLE\", table_obj.Name, table_description))        \n","        \n","        # Create a map of columns in the semantic model (case-insensitive)\n","        sem_columns = {c.Name.lower(): c for c in table_obj.Columns}\n","        \n","        # Update column descriptions from Excel\n","        for col_name, col_description in table_data[\"columns\"].items():\n","            col_name_lower = col_name.lower()\n","            \n","            if col_name_lower not in sem_columns:\n","                missing_columns.append(f\"{table_name}.{col_name}\")\n","                continue\n","            \n","            # Update column description\n","            column_obj = sem_columns[col_name_lower]\n","            if col_description:\n","                column_obj.Description = col_description\n","                updates_applied.append((\"COLUMN\", f\"{table_obj.Name}.{column_obj.Name}\", col_description))\n","        \n","        print(f\"✓ Processed table: {table_obj.Name}\")\n","\n","# Summary of updates\n","tables_with_updates = list(set([\n","    item[1].split('.')[0]\n","    for item in updates_applied\n","    if item[0] == \"COLUMN\"\n","]))\n","\n","columns_updated = [\n","    item[1]\n","    for item in updates_applied\n","    if item[0] == \"COLUMN\"\n","]\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"UPDATE SUMMARY\")\n","print(\"=\" * 80)\n","print(f\"\\nSemantic Model: '{SEMANTIC_MODEL_NAME}'\")\n","print(f\"Tables processed: {len(tables_with_updates)}\")\n","print(f\"Column descriptions updated: {len(columns_updated)}\")\n","\n","if missing_tables:\n","    print(f\"\\n⚠ TABLES NOT FOUND IN SEMANTIC MODEL ({len(missing_tables)}):\")\n","    for tbl in sorted(missing_tables):\n","        print(f\"  - {tbl}\")\n","\n","if missing_columns:\n","    print(f\"\\n⚠ COLUMNS NOT FOUND IN SEMANTIC MODEL ({len(missing_columns)}):\")\n","    for col in sorted(missing_columns):\n","        print(f\"  - {col}\")\n","\n","if tables_with_updates:\n","    print(f\"\\n✓ Tables updated: {', '.join(sorted(tables_with_updates))}\")\n","\n","print(\"\\n✓ Metadata update completed!\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"0bdfba23-0cec-47ef-90aa-50fdb43b8841","normalized_state":"finished","queued_time":"2025-12-08T20:50:44.412411Z","session_start_time":null,"execution_start_time":"2025-12-08T20:50:44.4136001Z","execution_finish_time":"2025-12-08T20:50:58.3365195Z","parent_msg_id":"c1412845-39d3-4b40-b028-82f646280e39"},"text/plain":"StatementMeta(, 0bdfba23-0cec-47ef-90aa-50fdb43b8841, 12, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✓ Processed table: accident\n✓ Processed table: adjuster\n✓ Processed table: claim\n✓ Processed table: driver_telemetry_data\n⚠ Table not found in semantic model: payment\n✓ Processed table: policy\n✓ Processed table: policyholder\n✓ Processed table: vehicle\n\n================================================================================\nUPDATE SUMMARY\n================================================================================\n\nSemantic Model: 'sm_AutoClaims'\nTables processed: 7\nColumn descriptions updated: 60\n\n⚠ TABLES NOT FOUND IN SEMANTIC MODEL (1):\n  - payment\n\n✓ Tables updated: accident, adjuster, claim, driver_telemetry_data, policy, policyholder, vehicle\n\n✓ Metadata update completed!\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3b8632c3-d68c-4b72-8e17-fd925dbe9b25"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"03795c9e-23af-4272-922d-5f4fec8a2e46"}],"default_lakehouse":"03795c9e-23af-4272-922d-5f4fec8a2e46","default_lakehouse_name":"lh_AutoClaims","default_lakehouse_workspace_id":"db7dcf85-001e-4277-a85e-3c92029900bc"}}},"nbformat":4,"nbformat_minor":5}