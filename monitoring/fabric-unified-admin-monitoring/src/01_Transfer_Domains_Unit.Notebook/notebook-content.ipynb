{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark",
      "jupyter_kernel_name": null
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "a365ComputeOptions": null,
    "sessionKeepAliveTimeout": 0,
    "dependencies": {
      "lakehouse": {
        "default_lakehouse": "6cff634b-88f7-3505-bed2-c03a36776a8b",
        "default_lakehouse_name": "FUAM_Lakehouse",
        "default_lakehouse_workspace_id": "88c8d9fa-2c24-3fad-8f46-b36431c7ba1d",
        "known_lakehouses": []
      },
      "environment": {}
    },
    "microsoft": {
      "language": "python",
      "language_group": "synapse_pyspark",
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "widgets": {},
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "spark_compute": {
      "compute_id": "/trident/default",
      "session_options": {
        "conf": {
          "spark.synapse.nbs.session.timeout": "1200000"
        }
      }
    }
  },
  "cells": [
    {
      "id": "8799783c-63df-4d42-943c-0112fa322084",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Capacities\n",
        "\n",
        "##### Data ingestion strategy:\n",
        "<mark style=\"background: #88D5FF;\">**REPLACE**</mark>\n",
        "\n",
        "##### Related pipeline:\n",
        "\n",
        "**Load_Capacities_E2E**\n",
        "\n",
        "##### Source:\n",
        "\n",
        "**Files** from FUAM_Lakehouse folder **bronze_file_location** variable\n",
        "\n",
        "##### Target:\n",
        "\n",
        "**1 Delta table** in FUAM_Lakehouse \n",
        "- **gold_table_name** variable value\n"
      ]
    },
    {
      "id": "0012ac3b-30c7-4b06-93c9-70c96d083539",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "from datetime import datetime, timedelta\n",
        "from pyspark.sql.functions import col, explode, upper\n",
        "from delta.tables import *\n",
        "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\",\"true\") # needed for automatic schema evolution in merge "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3830cbec-963f-4000-979a-cef97472b392",
      "cell_type": "code",
      "metadata": {
        "tags": [
          "parameters"
        ],
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "## Parameters\n",
        "display_data = True"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cfdf9ed3-2d15-4d34-ac89-de8304979562",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "## Variables\n",
        "bronze_file_location = f\"Files/raw/domains/\"\n",
        "silver_table_name = \"FUAM_Staging_Lakehouse.domains_silver\"\n",
        "gold_table_name = \"domains_flatten\"\n",
        "gold_table_name_with_prefix = f\"Tables/{gold_table_name}\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "19ea0d03-0e80-427e-90d7-4fb83989e860",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "# Clean Silver table, if exists\n",
        "if spark.catalog.tableExists(silver_table_name):\n",
        "    del_query = \"DELETE FROM \" + silver_table_name\n",
        "    spark.sql(del_query)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "69ce7ade-252c-41ab-9ecd-11e9b11c5a13",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "# Get Bronze data\n",
        "bronze_df = spark.read.option(\"multiline\", \"true\").json(bronze_file_location)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "755eeebb-7de3-4561-ac77-82aad0903c75",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": "",
        "collapsed": false
      },
      "source": [
        "if display_data:\n",
        "    display(bronze_df)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3e8e089c-9911-4d68-8301-bcdf1c89a2b1",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": "",
        "collapsed": false
      },
      "source": [
        "# Explode json subset structure\n",
        "exploded_df = bronze_df.select(explode(\"domains\").alias(\"d\"))\n",
        "\n",
        "# Extract json objects to tabular form\n",
        "extracted_df = exploded_df.select(col(\"d.*\"))\n",
        "\n",
        "extracted_df = extracted_df.withColumnRenamed(\"id\", \"DomainId\").withColumnRenamed(\"parentDomainId\", \"ParentDomainId\").withColumnRenamed(\"displayName\", \"DomainName\").withColumnRenamed(\"contributorsScope\", \"DomainContributorsScope\").withColumnRenamed(\"description\", \"DomainDescription\")\n",
        "silver_df = extracted_df.withColumn(\"DomainId\", upper(\"DomainId\")).withColumn(\"ParentDomainId\", upper(\"ParentDomainId\"))\n",
        "\n",
        "if display_data:\n",
        "    display(extracted_df)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a4e361be-8e12-4787-9669-fe98790d4397",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "# Write prepared bronze_df to silver delta table\n",
        "silver_df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(silver_table_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "063b983b-4611-4079-9a69-a87a3fddbc03",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": "",
        "collapsed": false
      },
      "source": [
        "# Get Silver table data for Domains - Flatten structure\n",
        "domains_generic_query = \"\"\"\n",
        "SELECT \n",
        "     gen.DomainId,\n",
        "     gen.DomainContributorsScope,\n",
        "     gen.DomainName AS OriginalDomainName,\n",
        "     gen.ParentDomainId AS OriginalParentDomainId,\n",
        "     CASE \n",
        "          WHEN gen.ParentDomainId IS NULL THEN gen.DomainName \n",
        "          ELSE md.DomainName\n",
        "     END AS MainDomainName,\n",
        "     CASE \n",
        "          WHEN gen.ParentDomainId IS NOT NULL THEN gen.DomainName \n",
        "          ELSE 'Without Subdomain'\n",
        "     END AS SubDomainName,\n",
        "     CASE \n",
        "          WHEN gen.ParentDomainId IS NOT NULL THEN 1 \n",
        "          ELSE 0 \n",
        "          END AS IsSubDomain     \n",
        "FROM \"\"\" + silver_table_name + \"\"\" AS gen LEFT OUTER JOIN \"\"\" + silver_table_name + \"\"\" AS md on gen.ParentDomainId = md.DomainId \"\"\"\n",
        "\n",
        "domains_generic_silver_df = spark.sql(domains_generic_query)\n",
        "\n",
        "if display_data:\n",
        "     display(domains_generic_silver_df)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c40a58fd-8b62-4f99-b3f3-0ba0d1fbbe77",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "domains_generic_silver_df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(f\"{gold_table_name}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6157f87b-de3d-4a63-a8f8-98b130f80da0",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "# Write history of bronze files\n",
        "mssparkutils.fs.cp(bronze_file_location, bronze_file_location.replace(\"Files/raw/\", \"Files/history/\") + datetime.now().strftime('%Y/%m/%d') + \"/\", True)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}