{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0fcaaa",
   "metadata": {},
   "source": [
    "# Feature Tracking - Setup Tables and Views\n",
    "\n",
    "**Purpose**: One-time setup for feature tracking tables and views\n",
    "\n",
    "**What this creates**:\n",
    "- ‚úÖ `feature_releases_roadmap` - Feature releases from Fabric GPS API (with roadmap)\n",
    "- ‚úÖ `preview_features_active` - Detected activated preview features\n",
    "- ‚úÖ `feature_alerts` - Alerts for new/risky preview features\n",
    "- ‚úÖ Helper SQL views for easy querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c91aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505200d2",
   "metadata": {},
   "source": [
    "## Step 1: Create `feature_releases_roadmap` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Creating table: feature_releases_roadmap\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS feature_releases_roadmap (\n",
    "        feature_id STRING NOT NULL,\n",
    "        feature_name STRING NOT NULL,\n",
    "        feature_description STRING,\n",
    "        workload STRING,\n",
    "        product_name STRING,\n",
    "        release_date TIMESTAMP,\n",
    "        release_type STRING,\n",
    "        release_status STRING,\n",
    "        is_preview BOOLEAN NOT NULL,\n",
    "        is_planned BOOLEAN NOT NULL,\n",
    "        is_shipped BOOLEAN NOT NULL,\n",
    "        last_modified TIMESTAMP NOT NULL,\n",
    "        source_url STRING,\n",
    "        source STRING,\n",
    "        extracted_date TIMESTAMP NOT NULL\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Table created: feature_releases_roadmap\")\n",
    "print(\"   Schema: 15 columns\")\n",
    "print(\"   üí° Includes planned/future features and historical tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49385cd0",
   "metadata": {},
   "source": [
    "## Step 2: Create `preview_features_active` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dcfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ Creating table: preview_features_active\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS preview_features_active (\n",
    "        setting_name STRING NOT NULL,\n",
    "        feature_id STRING NOT NULL,\n",
    "        feature_name STRING NOT NULL,\n",
    "        workload STRING,\n",
    "        similarity_score DOUBLE NOT NULL,\n",
    "        is_enabled BOOLEAN NOT NULL,\n",
    "        delegate_to_tenant BOOLEAN,\n",
    "        detected_date TIMESTAMP NOT NULL,\n",
    "        release_date TIMESTAMP,\n",
    "        release_status STRING,\n",
    "        source_url STRING,\n",
    "        days_since_release INT\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Table created: preview_features_active\")\n",
    "print(\"   Schema: 12 columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8337a78",
   "metadata": {},
   "source": [
    "## Step 3: Create `feature_alerts` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66383382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ Creating table: feature_alerts\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS feature_alerts (\n",
    "        alert_id STRING NOT NULL,\n",
    "        feature_id STRING NOT NULL,\n",
    "        feature_name STRING NOT NULL,\n",
    "        workload STRING,\n",
    "        alert_type STRING NOT NULL,\n",
    "        severity STRING NOT NULL,\n",
    "        message STRING NOT NULL,\n",
    "        setting_name STRING,\n",
    "        similarity_score DOUBLE,\n",
    "        days_since_release INT,\n",
    "        alert_date TIMESTAMP NOT NULL,\n",
    "        acknowledged BOOLEAN NOT NULL,\n",
    "        acknowledged_date TIMESTAMP,\n",
    "        acknowledged_by STRING\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Table created: feature_alerts\")\n",
    "print(\"   Schema: 14 columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21110f70",
   "metadata": {},
   "source": [
    "## Step 4: Create Helper SQL Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ Creating helper SQL views...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# View 1: Roadmap Upcoming Features\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE VIEW vw_roadmap_upcoming AS\n",
    "    SELECT \n",
    "        feature_name,\n",
    "        feature_description,\n",
    "        product_name,\n",
    "        workload,\n",
    "        release_type,\n",
    "        release_status,\n",
    "        release_date,\n",
    "        is_preview,\n",
    "        is_planned,\n",
    "        last_modified,\n",
    "        CASE \n",
    "            WHEN release_date IS NULL THEN NULL\n",
    "            ELSE DATEDIFF(release_date, CURRENT_DATE())\n",
    "        END as days_until_release\n",
    "    FROM feature_releases_roadmap\n",
    "    WHERE is_planned = true\n",
    "      AND (release_date IS NULL OR release_date >= CURRENT_DATE())\n",
    "    ORDER BY release_date ASC NULLS LAST, last_modified DESC\n",
    "\"\"\")\n",
    "print(\"‚úÖ vw_roadmap_upcoming - Planned/upcoming features\")\n",
    "\n",
    "# View 2: Active Preview Features\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE VIEW vw_active_preview_features AS\n",
    "    SELECT \n",
    "        feature_name,\n",
    "        workload,\n",
    "        setting_name,\n",
    "        days_since_release,\n",
    "        similarity_score,\n",
    "        release_date,\n",
    "        detected_date,\n",
    "        is_enabled\n",
    "    FROM preview_features_active\n",
    "    WHERE is_enabled = true\n",
    "    ORDER BY detected_date DESC\n",
    "\"\"\")\n",
    "print(\"‚úÖ vw_active_preview_features - Currently enabled previews\")\n",
    "\n",
    "# View 3: Critical Alerts\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE VIEW vw_critical_alerts AS\n",
    "    SELECT \n",
    "        alert_id,\n",
    "        feature_name,\n",
    "        workload,\n",
    "        alert_type,\n",
    "        severity,\n",
    "        message,\n",
    "        alert_date,\n",
    "        acknowledged\n",
    "    FROM feature_alerts\n",
    "    WHERE acknowledged = false \n",
    "      AND severity IN ('Critical', 'Warning')\n",
    "    ORDER BY \n",
    "        CASE severity \n",
    "            WHEN 'Critical' THEN 1 \n",
    "            WHEN 'Warning' THEN 2 \n",
    "            ELSE 3 \n",
    "        END,\n",
    "        alert_date DESC\n",
    "\"\"\")\n",
    "print(\"‚úÖ vw_critical_alerts - Unacknowledged critical/warning alerts\")\n",
    "\n",
    "# View 4: Feature Release Timeline\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE VIEW vw_feature_timeline AS\n",
    "    SELECT \n",
    "        feature_name,\n",
    "        product_name,\n",
    "        workload,\n",
    "        release_type,\n",
    "        release_status,\n",
    "        is_preview,\n",
    "        is_planned,\n",
    "        is_shipped,\n",
    "        release_date,\n",
    "        CASE \n",
    "            WHEN release_date IS NULL THEN NULL\n",
    "            ELSE DATEDIFF(CURRENT_DATE(), release_date)\n",
    "        END as days_since_release,\n",
    "        last_modified\n",
    "    FROM feature_releases_roadmap\n",
    "    ORDER BY release_date DESC NULLS LAST\n",
    "\"\"\")\n",
    "print(\"‚úÖ vw_feature_timeline - Complete release timeline\")\n",
    "\n",
    "print(\"\\n‚úÖ All SQL views created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af215ea",
   "metadata": {},
   "source": [
    "## ‚úÖ Setup Complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7dc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ FEATURE TRACKING SETUP COMPLETED!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verify tables\n",
    "tables = [\"feature_releases_roadmap\", \"preview_features_active\", \"feature_alerts\"]\n",
    "print(\"\\nüìã Tables created:\")\n",
    "for table in tables:\n",
    "    try:\n",
    "        count = spark.read.format(\"delta\").table(table).count()\n",
    "        print(f\"  ‚úÖ {table}: {count} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå {table}: ERROR - {e}\")\n",
    "\n",
    "# Verify views\n",
    "views = [\"vw_roadmap_upcoming\", \"vw_active_preview_features\", \"vw_critical_alerts\", \"vw_feature_timeline\"]\n",
    "print(\"\\nüìã Views created:\")\n",
    "for view in views:\n",
    "    try:\n",
    "        spark.sql(f\"SELECT * FROM {view} LIMIT 1\")\n",
    "        print(f\"  ‚úÖ {view}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå {view}: ERROR - {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìö Next Step:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n  ‚Üí Run 'Load_Feature_Tracking' notebook to populate the tables\")\n",
    "print(\"\\nüí° Schedule Load_Feature_Tracking to run daily for continuous monitoring\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
